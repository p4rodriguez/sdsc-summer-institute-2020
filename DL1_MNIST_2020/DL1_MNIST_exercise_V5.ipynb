{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an exercise in using convolulation networks with the MNIST dataset.  It will provide some introduction and practice in setting up and assigning parameter values.\n",
    "\n",
    "The exercise is to run through all the cells - one of the last cells produces images of the filters\n",
    "\n",
    "Try changing the size of the filters and number of filters in the first convolution layer add statement.  (Look for the 'EXERCISE' comments and the <<<<-----  markers)\n",
    "\n",
    "Compare how the filters are different when you use 3x3 filters vs something like 16x16\n",
    "\n",
    "The last cell looks at the convolution layer activation - it is a transformation of the input - check it out and you might see interesting features highlighted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  MNIST tutorial (handwritten printed digits recognition tutorial)\n",
    "#  (more or less from Chollet's book)\n",
    "\n",
    "# ----------- IMPORT STATEMENTS ---------------\n",
    "import numpy as np\n",
    "np.random.seed(1)  # for reproducibility\n",
    "import matplotlib.pyplot as plt      #These provide matlab type of plotting functions\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from keras.models import Sequential               #Sequential models are the standard stack of layers models\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten   #These are core layer specification functions\n",
    "from keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D           #These are convolution layer functions\n",
    "from keras.utils import np_utils                         #Some utilities\n",
    "from keras import optimizers                             #For training algorithm\n",
    "\n",
    "from keras import backend as K    #backend is tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "#---------------------------------------------\n",
    "print('import done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------- LOAD and PREPARE DATA STATEMENTS ----------------\n",
    "# Load some numpy arrays that have the MNIST data\n",
    "#  (these are subsets extracted from the MNIST data set in Keras)\n",
    "X_train=np.load('X_train5k.npy')\n",
    "Y_train=np.load('Y_train5k.npy')\n",
    "X_test =np.load('X_test.npy')\n",
    "Y_test =np.load('Y_test.npy')\n",
    "\n",
    "print(X_train.shape)     #review the dimensions Note python3 uses print(X..) python 2 uses print X...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Reshape input data ----------------\n",
    "#  b/c Keras expects N-3D images (ie 4D matrix)\n",
    "# ----------------------------------------------\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test  = X_test.reshape(X_test.shape[0],   1, 28, 28)\n",
    "\n",
    "#To confirm, we can print X_train's dimensions again:\n",
    "print(X_train.shape)\n",
    "\n",
    "#convert and put into 0-1 range\n",
    "X_train  = X_train.astype('float32')\n",
    "X_test   = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test  /= 255\n",
    "\n",
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "Y_train = np_utils.to_categorical(Y_train, 10)\n",
    "Y_test  = np_utils.to_categorical(Y_test,  10)\n",
    "\n",
    "# ------------- End loading and preparing data --------------\n",
    "print(\"min Xtrain:\"+str(np.amin(X_train)))   #this gets the max value over a flattened numpy array\n",
    "print(\"max Xtrain:\"+str(np.amax(X_train)))   #this gets the max value over a flattened numpy array\n",
    "print('prep done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "# --------------Set up Model ---------------------\n",
    "# ----------------------------------------------\n",
    "mymodel = Sequential()\n",
    "\n",
    "numfilters = 32  #<<<< -------- EXERCISE: you can try 8,16,32 for comparison\n",
    "                 #numbers that divide into 32 are better for GPUs so its often recommended\n",
    "\n",
    "#     input shape for 1 image, channels refers to color dimension of input image\n",
    "mymodel.add(Convolution2D(numfilters, (3,3),strides=1,  data_format=\"channels_first\",\n",
    "                          activation='relu', input_shape=(1,28,28))) \n",
    "#                                       /\\ \n",
    "#                                       /\\\n",
    "#                                       |--------EXERCISE:try filter size to 9,9 16,16 \n",
    "#                                                      and check accuracy\n",
    " \n",
    "print('modeldef and first conv layer done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel.layers[0].output # use this to check sizes of output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "#-----------------Now add more Convolution layers\n",
    "# ----------------------------------------------\n",
    "mymodel.add(Convolution2D(numfilters, (3, 3), strides=1, data_format=\"channels_first\", activation='relu'))\n",
    "\n",
    "mymodel.add(MaxPooling2D(pool_size=(2,2),strides=2,data_format=\"channels_first\")) #get Max over 2D region,and slide\n",
    "mymodel.add(Dropout(0.25))\n",
    " \n",
    "mymodel.add(Flatten())            #reorganize 2DxFilters output into 1D\n",
    "print('added more layers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel.layers[1].output   #size of output layer for max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------Now add final classification layers\n",
    "mymodel.add(Dense(32, activation='relu'))  #enter number of hidden units (no good rule, but start with ~ num of previous output) \n",
    "\n",
    "\n",
    "mymodel.add(Dropout(0.25))\n",
    "mymodel.add(Dense(10, activation='softmax'))\n",
    "print('assemble model done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Now assemble (ie compile TensorFlow commands) and run -----\n",
    "mymodel.compile(loss='categorical_crossentropy',\n",
    "               optimizer='adam',  #NOTE, adam is adative learn.rate, sgd is stoch.grad.descent\n",
    "                                  #    adam is usually much faster training\n",
    "               metrics=['accuracy'])\n",
    "print('compiled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now train the model, and use early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#Stop if there's no improvement after 5 epochs\n",
    "ES_function    = EarlyStopping(monitor='val_acc', mode='max', patience=5) #or min_delta=1)\n",
    "\n",
    "#Save model weights at stopping point only\n",
    "ModCk_function = ModelCheckpoint('es_best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "#Fit the model, use 20% of data to get validation score\n",
    "history=mymodel.fit(X_train, Y_train, validation_split=0.20,\n",
    "          batch_size=32, epochs=50, verbose=1,callbacks=[ES_function,ModCk_function])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history and print out performance\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val_test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val_test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "#--------- Get overall prediction score on training and test sets\n",
    "# ---------------------------------------------------------------------\n",
    "from keras.models import load_model\n",
    "mymodel_best = load_model('es_best_model.h5')\n",
    "# evaluate the model\n",
    "\n",
    "\n",
    "trainscore = mymodel_best.evaluate(X_train, Y_train, verbose=1) # get overal score\n",
    "testscore  = mymodel_best.evaluate(X_test, Y_test, verbose=1) # get overal score\n",
    "#somepred  = mymodel.predict(X_test,verbose=0)           # use this get prediction values\n",
    "\n",
    "print('Train Loss: %.3f, Train Acc: %.3f' % (trainscore[0], trainscore[1]))\n",
    "print('Test Loss: %.3f, Test Acc: %.3f' % (testscore[0], testscore[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the sample of training image ----\n",
    "img_filename = \"Xtrain_num0_cat_5.jpeg\" #% scriptDir \n",
    "#img_filename = \"Xtrain_num1_cat_0.jpeg\" #% scriptDir \n",
    "im = mpimg.imread(img_filename)\n",
    "plt.figure()\n",
    "plt.imshow(im,'gray')\n",
    "plt.show()\n",
    "#print('im loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ GET WEIGHTS From Convolution Layer and make mosaic image \n",
    "Wlist   =mymodel.layers[0].get_weights()      \n",
    "W3D     =np.squeeze(Wlist[0])\n",
    "print(\"W3D shape Wlist[0]:\"+str(W3D.shape))\n",
    "W3Dchan =W3D.swapaxes(1,2).swapaxes(0,1)  #get the channels as 1st dimension;\n",
    "\n",
    "Wmin       =np.amin(W3Dchan)\n",
    "Wmax       =np.amax(W3Dchan-Wmin)\n",
    "Wsc        =np.int_(255*(W3Dchan-Wmin)/Wmax)\n",
    "ncol =4\n",
    "nrow =np.ceil(numfilters/ncol)\n",
    "print(nrow)\n",
    "plt.figure()\n",
    "for i in range(Wsc.shape[0]):\n",
    "   plt.subplot(nrow,ncol,i+1)\n",
    "   plt.imshow(Wsc[i],'gray')\n",
    "   plt.axis('off')\n",
    "#plt.savefig(\"test.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "print('done plotting weights mosaic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ---------------- NOW Visualize the activations for the first training example --------\n",
    "#   first gather activations from the model layers\n",
    "# -------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "from keras import models   \n",
    "\n",
    "layer_outputs     = [layer.output for layer in mymodel.layers[:]]\n",
    "my_model_actvtns  = models.Model(inputs=mymodel.input, outputs=layer_outputs)\n",
    "\n",
    "x                 = np.expand_dims(X_train[0],0)           #set up a 4D input of 1 image training set \n",
    "\n",
    "my_actvtns_output = my_model_actvtns.predict(x)   #for each image get predictions/activatns\n",
    "\n",
    "print(len(my_actvtns_output))\n",
    "for act_lay in my_actvtns_output:  #[lay2do]:\n",
    "        print(act_lay.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Now output a mosaic of layer 0 output\n",
    "layeroutput3D      = np.squeeze(my_actvtns_output[0])      \n",
    "ncol =4\n",
    "nrow =np.ceil(numfilters/ncol)\n",
    "plt.figure()\n",
    "for i in range(layeroutput3D.shape[0]):\n",
    "   plt.subplot(nrow,ncol,i+1)\n",
    "   plt.imshow(layeroutput3D[i],'gray')\n",
    "   plt.axis('off')\n",
    "#plt.savefig(\"test.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "print('done plotting layer activation output mosaic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
